{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "encoder.fit([[0], [1]]) \n",
    "\n",
    "# 0 - Tumor\n",
    "# 1 - Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating an Encoder Object:\n",
    "  - An instance of the OneHotEncoder class is created and stored in the variable `encoder`.\n",
    "\n",
    "- Fitting the Encoder:\n",
    "  - The `fit()` method is used to teach the encoder about the categories it will encode.\n",
    "  - The data [[0], [1]] is provided, indicating two categories: 0 and 1.\n",
    "\n",
    "- Mapping Categories to Labels:\n",
    "  - Categories 0 and 1 are labeled as \"Tumor\" and \"Normal\" respectively.\n",
    "\n",
    "- One-Hot Encoding:\n",
    "  - One-hot encoding converts categorical data into binary vectors.\n",
    "  - Each category gets its binary representation with one \"hot\" (1) and all others \"cold\" (0).\n",
    "\n",
    "- Usage:\n",
    "  - After fitting with [[0], [1]], the encoder can transform categorical data.\n",
    "  - For example, [[0]] becomes [[1, 0]], and [[1]] becomes [[0, 1]].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell updates result list for images with tumor\n",
    "\n",
    "data = []\n",
    "paths = []\n",
    "result = []\n",
    "\n",
    "for r, d, f in os.walk(r'/Users/kartiksethi/Desktop/Mritumor/brain_tumor_dataset/yes'):\n",
    "    for file in f:\n",
    "        if '.jpg' in file:\n",
    "            paths.append(os.path.join(r, file))\n",
    "\n",
    "for path in paths:\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((128,128))\n",
    "    img = np.array(img)\n",
    "    if(img.shape == (128,128,3)):\n",
    "        data.append(np.array(img))\n",
    "        result.append(encoder.transform([[0]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell updates result list for images without tumor\n",
    "\n",
    "paths = []\n",
    "for r, d, f in os.walk(r\"/Users/kartiksethi/Desktop/Mritumor/brain_tumor_dataset/no\"):\n",
    "    for file in f:\n",
    "        if '.jpg' in file:\n",
    "            paths.append(os.path.join(r, file))\n",
    "\n",
    "for path in paths:\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((128,128))\n",
    "    img = np.array(img)\n",
    "    if(img.shape == (128,128,3)):\n",
    "        data.append(np.array(img))\n",
    "        result.append(encoder.transform([[1]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.array(result)\n",
    "result = result.reshape(128,128,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data, result, test_size=0.2, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), input_shape=(128, 128, 3), padding = 'Same'))\n",
    "model.add(Conv2D(32, kernel_size=(2, 2),  activation ='relu', padding = 'Same'))\n",
    "\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\n",
    "model.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer='Adamax')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 30, batch_size = 40, verbose = 1,validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Test', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def names(number):\n",
    "    if number==0:\n",
    "        return 'Its a Tumor'\n",
    "    else:\n",
    "        return 'No, Its not a tumor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def names(number):\n",
    "    if number==0:\n",
    "        return 'Its a Tumor'\n",
    "    else:\n",
    "        return 'No, Its not a tumor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "# from matplotlib import pyplot as plt\n",
    "# from IPython.display import display\n",
    "# import time\n",
    "# from PIL import Image\n",
    "\n",
    "# # Define the function to get the class name\n",
    "# def names(classification):\n",
    "#     if classification == 0:\n",
    "#         return \"Tumor\"\n",
    "#     elif classification == 1:\n",
    "#         return \"Normal\"\n",
    "#     else:\n",
    "#         return \"Unknown\"\n",
    "\n",
    "# # Read the model\n",
    "# # Assuming you have already loaded and compiled your Keras model and named it 'model'\n",
    "\n",
    "# # Define the paths to the images\n",
    "# image_paths = [\n",
    "#     '/Users/kartiksethi/Desktop/Mritumor/brain_tumor_dataset/blur/Brain.jpg'\n",
    "# ]\n",
    "\n",
    "# # Loop through each image path\n",
    "# for image_path in image_paths:\n",
    "#     # Reading the image\n",
    "#     img = cv2.imread(image_path)\n",
    "\n",
    "#     # Denoising the image using median filter\n",
    "#     dst = cv2.medianBlur(img, 5)  # Adjust kernel size as needed\n",
    "\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     # Plotting the original and denoised image\n",
    "#     plt.subplot(121), plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "#     plt.title('Original Image')\n",
    "#     plt.subplot(122), plt.imshow(cv2.cvtColor(dst, cv2.COLOR_BGR2RGB))\n",
    "#     plt.title('Denoised Image')\n",
    "\n",
    "#     end_time = time.time()\n",
    "\n",
    "#     plt.show()\n",
    "#     execution_time = end_time - start_time\n",
    "#     print(\"Execution time for denoising:\", execution_time, \"seconds\")\n",
    "\n",
    "#     # Reading the image for classification\n",
    "#     img = Image.open(image_path)\n",
    "#     x = np.array(img.resize((128,128)))\n",
    "#     x = x.reshape(1,128,128,3)\n",
    "    \n",
    "#     start_time = time.time()\n",
    "\n",
    "#     # Predicting the class\n",
    "#     res = model.predict_on_batch(x)\n",
    "#     classification = np.argmax(res)\n",
    "\n",
    "#     end_time = time.time()\n",
    "\n",
    "#     # Displaying the image and prediction\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "\n",
    "#     execution_time = end_time - start_time\n",
    "#     print(\"Execution time for classification:\", execution_time, \"seconds\")\n",
    "#     print(\"Confidence This Is \" + names(classification) + \": \" + str(res[0][classification]*100) + \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "img = Image.open(r\"/Users/kartiksethi/Desktop/Mritumor/brain_tumor_dataset/yes/Y6.jpg\")\n",
    "x = np.array(img.resize((128,128)))\n",
    "x = x.reshape(1,128,128,3)\n",
    "res = model.predict_on_batch(x)\n",
    "classification = np.where(res == np.amax(res))[1][0]\n",
    "imshow(img)\n",
    "print(str(res[0][classification]*100) + '% Confidence This Is A ' + names(classification))\n",
    "model.save('loc.keras') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model=keras.models.load_model('loc.keras')\n",
    "from matplotlib.pyplot import imshow\n",
    "img = Image.open(r\"brain_tumor_dataset/yes/Y3.jpg\")\n",
    "x = np.array(img.resize((128,128)))\n",
    "x = x.reshape(1,128,128,3)\n",
    "res = loaded_model.predict_on_batch(x)\n",
    "classification = np.where(res == np.amax(res))[1][0]\n",
    "imshow(img)\n",
    "print(str(res[0][classification]*100) + '% Confidence This Is A ' + names(classification))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
