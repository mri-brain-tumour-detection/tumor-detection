{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 23:17:04.361510: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-15 23:17:04.363639: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-15 23:17:04.474678: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-15 23:17:04.899799: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-15 23:17:05.904063: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "encoder.fit([[0], [1]]) \n",
    "\n",
    "# 0 - Tumor\n",
    "# 1 - Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating an Encoder Object:\n",
    "  - An instance of the OneHotEncoder class is created and stored in the variable `encoder`.\n",
    "\n",
    "- Fitting the Encoder:\n",
    "  - The `fit()` method is used to teach the encoder about the categories it will encode.\n",
    "  - The data [[0], [1]] is provided, indicating two categories: 0 and 1.\n",
    "\n",
    "- Mapping Categories to Labels:\n",
    "  - Categories 0 and 1 are labeled as \"Tumor\" and \"Normal\" respectively.\n",
    "\n",
    "- One-Hot Encoding:\n",
    "  - One-hot encoding converts categorical data into binary vectors.\n",
    "  - Each category gets its binary representation with one \"hot\" (1) and all others \"cold\" (0).\n",
    "\n",
    "- Usage:\n",
    "  - After fitting with [[0], [1]], the encoder can transform categorical data.\n",
    "  - For example, [[0]] becomes [[1, 0]], and [[1]] becomes [[0, 1]].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell updates result list for images with tumor\n",
    "\n",
    "data = []\n",
    "paths = []\n",
    "result = []\n",
    "\n",
    "for r, d, f in os.walk(r'brain_tumor_dataset/yes'):\n",
    "    for file in f:\n",
    "        if '.jpg' in file:\n",
    "            paths.append(os.path.join(r, file))\n",
    "\n",
    "for path in paths:\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((128,128))\n",
    "    img = np.array(img)\n",
    "    if(img.shape == (128,128,3)):\n",
    "        data.append(np.array(img))\n",
    "        result.append(encoder.transform([[0]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell updates result list for images without tumor\n",
    "\n",
    "paths = []\n",
    "for r, d, f in os.walk(r\"brain_tumor_dataset/no\"):\n",
    "    for file in f:\n",
    "        if '.jpg' in file:\n",
    "            paths.append(os.path.join(r, file))\n",
    "\n",
    "for path in paths:\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((128,128))\n",
    "    img = np.array(img)\n",
    "    if(img.shape == (128,128,3)):\n",
    "        data.append(np.array(img))\n",
    "        result.append(encoder.transform([[1]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 5977 into shape (139,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m downsampled_result \u001b[38;5;241m=\u001b[39m flattened_result[:\u001b[38;5;241m139\u001b[39m \u001b[38;5;241m*\u001b[39m downsampling_factor]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Reshape the downsampled array to the desired shape\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m reshaped_result \u001b[38;5;241m=\u001b[39m \u001b[43mdownsampled_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m139\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 5977 into shape (139,2)"
     ]
    }
   ],
   "source": [
    "result = np.array(result)\n",
    "result = result.reshape(139,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data, result, test_size=0.2, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), input_shape=(128, 128, 3), padding = 'Same'))\n",
    "model.add(Conv2D(32, kernel_size=(2, 2),  activation ='relu', padding = 'Same'))\n",
    "\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\n",
    "model.add(Conv2D(64, kernel_size = (2,2), activation ='relu', padding = 'Same'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer='Adamax')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 30, batch_size = 40, verbose = 1,validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Test', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def names(number):\n",
    "    if number==0:\n",
    "        return 'Its a Tumor'\n",
    "    else:\n",
    "        return 'No, Its not a tumor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def names(number):\n",
    "    if number==0:\n",
    "        return 'Its a Tumor'\n",
    "    else:\n",
    "        return 'No, Its not a tumor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "# from matplotlib import pyplot as plt\n",
    "# from IPython.display import display\n",
    "# import time\n",
    "# from PIL import Image\n",
    "\n",
    "# # Define the function to get the class name\n",
    "# def names(classification):\n",
    "#     if classification == 0:\n",
    "#         return \"Tumor\"\n",
    "#     elif classification == 1:\n",
    "#         return \"Normal\"\n",
    "#     else:\n",
    "#         return \"Unknown\"\n",
    "\n",
    "# # Read the model\n",
    "# # Assuming you have already loaded and compiled your Keras model and named it 'model'\n",
    "\n",
    "# # Define the paths to the images\n",
    "# image_paths = [\n",
    "#     '/Users/kartiksethi/Desktop/Mritumor/brain_tumor_dataset/blur/Brain.jpg'\n",
    "# ]\n",
    "\n",
    "# # Loop through each image path\n",
    "# for image_path in image_paths:\n",
    "#     # Reading the image\n",
    "#     img = cv2.imread(image_path)\n",
    "\n",
    "#     # Denoising the image using median filter\n",
    "#     dst = cv2.medianBlur(img, 5)  # Adjust kernel size as needed\n",
    "\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     # Plotting the original and denoised image\n",
    "#     plt.subplot(121), plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "#     plt.title('Original Image')\n",
    "#     plt.subplot(122), plt.imshow(cv2.cvtColor(dst, cv2.COLOR_BGR2RGB))\n",
    "#     plt.title('Denoised Image')\n",
    "\n",
    "#     end_time = time.time()\n",
    "\n",
    "#     plt.show()\n",
    "#     execution_time = end_time - start_time\n",
    "#     print(\"Execution time for denoising:\", execution_time, \"seconds\")\n",
    "\n",
    "#     # Reading the image for classification\n",
    "#     img = Image.open(image_path)\n",
    "#     x = np.array(img.resize((128,128)))\n",
    "#     x = x.reshape(1,128,128,3)\n",
    "    \n",
    "#     start_time = time.time()\n",
    "\n",
    "#     # Predicting the class\n",
    "#     res = model.predict_on_batch(x)\n",
    "#     classification = np.argmax(res)\n",
    "\n",
    "#     end_time = time.time()\n",
    "\n",
    "#     # Displaying the image and prediction\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "\n",
    "#     execution_time = end_time - start_time\n",
    "#     print(\"Execution time for classification:\", execution_time, \"seconds\")\n",
    "#     print(\"Confidence This Is \" + names(classification) + \": \" + str(res[0][classification]*100) + \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "img = Image.open(r\"/Users/kartiksethi/Desktop/Mritumor/brain_tumor_dataset/yes/Y6.jpg\")\n",
    "x = np.array(img.resize((128,128)))\n",
    "x = x.reshape(1,128,128,3)\n",
    "res = model.predict_on_batch(x)\n",
    "classification = np.where(res == np.amax(res))[1][0]\n",
    "imshow(img)\n",
    "print(str(res[0][classification]*100) + '% Confidence This Is A ' + names(classification))\n",
    "model.save('loc.keras') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model=keras.models.load_model('loc.keras')\n",
    "from matplotlib.pyplot import imshow\n",
    "img = Image.open(r\"brain_tumor_dataset/yes/Y3.jpg\")\n",
    "x = np.array(img.resize((128,128)))\n",
    "x = x.reshape(1,128,128,3)\n",
    "res = loaded_model.predict_on_batch(x)\n",
    "classification = np.where(res == np.amax(res))[1][0]\n",
    "imshow(img)\n",
    "print(str(res[0][classification]*100) + '% Confidence This Is A ' + names(classification))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
